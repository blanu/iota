# Thoughts on Portability

There are many different target platforms. In the early days, these targets were machine architectures, and then instruction set architectures (ISAs) otherwise known as assembly languages, but we never left behind the machine architectures. Then C came along and the targets were different compilers but we still need the ISAs because you can embed assembly in C. Then Arduino came along, which is kind of C, and it abstracts some of the platform-specific stuff but also exposes you to the platform-specific stuff. In the modern era, not all target platforms are C. Of course you have Javascript in web browsers, but also Swift on iOS and Kotlin on Android. The operating systems expose certain APIs to the high-level languages that they do not provide C bindings for, so this is a new level of abstraction.

There was an era in there where Smalltalk had some influence, particularly in it's incarnation as Java. The current dominant force in this family is Python. In this paradigm, you target a virtual machine architecture and the bytecodes of it's ISA instead of the physical machine. Smalltalk was it's own thing, but as it evolves into Java and then Python we eventually get back to just being a wrapper around C, particularly in the case of the numpy era of Python.

The latest generation of mainstream production languages like Swift, Kotlin, and Go, are trying to move beyond C bindings to fully take over C's place of prominence. You can see this in the tendency for Rust developers to attempt to rewrite everything written in C in Rust. You would never have a C programmer rewriting their algorithms in Python. What purpose would this serve, to make it slower? The key to Python performance optimization is to spend all of your in C-land and just glue bits of C together with Python, as in the humpy experience. However, you see the same patterns of rewriting everything in the Swift and Go communities, although perhaps not as fervently as the Rust folks.

It is very difficult to completely abandon C, ISAs, or machine architectures, though. This is because code is generally not at all very portable. Layers of abstraction are leaky, so while they are intended to same time and effort, unless they are meticulously designed, as in Smalltalk, APL, and Lisp, you end up handling both all the complexity of the high-level abstraction and all the minutia of the low-level stuff. You have to because without the high-level stuff your code won't compile and without the low-level stuff your code won't be correct or won't perform well due to various leaky abstraction. Performance is a leak in the abstraction, so is security.

As a pretty fundamental example, consider effects. If your program is going to do anything other than pure computation, then you need effects. Effects are implemented as syscalls, and syscalls are C functions. So, if you want to have effects, then you need C. This is not completely true, though, because all abstractions are fundamentally permeable anyway. So what you need isn't C, it's the C function calling convention, which is necessarily implemented in assembly. So, if you're willing to write your own assembly, then you can all syscalls but just recreating the exact part of C that you need. Of course, this means that you need a compiler, a linked, the whole deal. Most people won't go that far, and even if you did, how many platforms would your compiler support? C (of some kind) runs on pretty everything (in some fashion). Are you going to implement syscalls in assembly on every processor of interest? Or will your language be limited to one platform, in other words not portable?

Unfortunately, targeting C won't get you there either, because C is quite a leaky abstraction. Of prime importance is that C allows for several platform-specific architectural differences, such as word size, endianness, and alignment. What is the maximum value of an ```int``` in C? Well, it depends on the platform. So a C ```int``` is not really a type, it's a family of types that depends on the platform. C code is therefore not portable by default. C programs compiled on different ISAs will give different results, and your program may or may not give correct output. Of course, there is nothing forcing you to use the ```int``` type. You could use ```uint32_t``` instead. Now we are at a new level of abstraction once again, which we might call portable C. Unfortunately, this doesn't necessarily get us anywhere, due to leaky abstractions. If you never use an ```int``` then that means you must also never use any library dependencies, because those libraries could use and ```int```, and writing C without libraries would be in the category of meticulously-crafted abstractions that are more trouble than is worth it for most people.

So how do you write portable code, ever? The answer is that someone has to create and maintain the aforementioned meticulously-crafted abstraction layer, and no exceptions can be made to allow access to the low-level stuff anymore. Once you piece the veil by admitting an exception, you have to deal with the possibility that it's present in the current code forevermore and you lose all the ground that you would have gained. Of course, just because you have created an abstraction layer with the possibility of portability, that doesn't mean that it's actually portable. You'd also have to design it correctly.

# What's a good abstraction for portability?

The first goal of portability should be to remove any dependencies on the ISA, such as word size, endianness, etc. To start, this means implementing bigints and using them for computations instead of word-sized integers. This doesn't mean that you can't have performance as well. Performance will also be a leak in the abstraction. One nitpick of an exception to this would be a cryptographically secure architecture where all operations take the same amount of time in order to avoid side channel attacks. This could only be implemented by slowing down the fastest operations to the same speed as the slowest operations. You can have performance through specialization. For instance, you can have both word-sized integers and bigints and use autopromotion, as Python does. This let's you use the fast path for small integers and the slow path for big ones. This is fine, as long as you provide the exact same API for both representations of integers. It's not that hard to give two things the same API. Smalltalk and Lisp were a pioneers in this approach. When you call a late-bound function in these languages, you get some particular implementation of that abstract operation that could be completely different for each type of value. Haskell-like languages take this to the next level by letting you define implementations based on the types of all of the function's arguments. This allows you to do math not just on bigint or word-sized ints, but also between the two, preserving the abstraction that they are interchangeable.

However, you can't just write portable C anymore, because as I said before these days not all APIs you might want to target are even available to call from C. While you should feel free to port all of the algorithms you want to your language of choice, you can't port effects. Either the effect is callable from the implementation language, or it's not. I first recall seeing this effect in C++, which mysteriously didn't allow you to write functions that are callable from C. If I recall correctly, this feature of C++ is known as function name mangling. While some modern languages like Go have fought back against this injustice, with things like CGo (which let's you write functions in Go that are callable from C), I once saw a persuasive developer convince a roomful of C programmers that CGo should not be used because of the performance hit of calling Go functions from C (the leaky abstraction of performance). By the way, I do not advocate this position, and I would advise you to base your implementation choices on actual performance benchmarks rather than a charismatic debate.

So, the conclusion might not be obvious, but it's that you should target the layer of abstraction that has access to the effects, because ultimately the purpose of programs is to create effects. Computations are the plumbing that choose which effects to trigger and when. If you don't have access to the effects, then you can't win. As I said before, not all effects are available from C on all platforms anymore. Therefore, the optimal target for portability is multiple difference languages rather than multiple machine architectures, ISAs, or C compilers. Not only do the languages that have access to the effects allow your program to share that access, but they also have generally been ported to multiple machine architectures and ISAs anyway, all for free for you. An example of this is C and syscalls. You can call syscalls in C from lots of different machine architectures and ISAs. Similarly, Swift runs on all Apple products, x86 or ARM, and Kotlin runs on all Android phones, which encompass a wide variety of machine architectures and ISAs (mostly ARM).
